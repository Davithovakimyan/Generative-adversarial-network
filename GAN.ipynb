{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc0ad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from cv2 import imread, resize\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_lfw_dataset(attrs_name = \"lfw_attributes.txt\",\n",
    "                      images_name = \"lfw-deepfunneled\",\n",
    "                      raw_images_name = \"lfw\",\n",
    "                      use_raw=False,\n",
    "                      dx=80,dy=80,\n",
    "                      dimx=45,dimy=45\n",
    "    ):#sad smile\n",
    "\n",
    "    #download if not exists\n",
    "    if (not use_raw) and not os.path.exists(images_name):\n",
    "        print(\"images not found, donwloading...\")\n",
    "        os.system(\"wget http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz -O tmp.tgz\")\n",
    "        print(\"extracting...\")\n",
    "        os.system(\"tar xvzf tmp.tgz && rm tmp.tgz\")\n",
    "        print(\"done\")\n",
    "        assert os.path.exists(images_name)\n",
    "\n",
    "    if use_raw and not os.path.exists(raw_images_name):\n",
    "        print(\"images not found, donwloading...\")\n",
    "        os.system(\"wget http://vis-www.cs.umass.edu/lfw/lfw.tgz -O tmp.tgz\")\n",
    "        print(\"extracting...\")\n",
    "        os.system(\"tar xvzf tmp.tgz && rm tmp.tgz\")\n",
    "        print(\"done\")\n",
    "        assert os.path.exists(raw_images_name)\n",
    "\n",
    "    if not os.path.exists(attrs_name):\n",
    "        print(\"attributes not found, downloading...\")\n",
    "        os.system(\"wget http://www.cs.columbia.edu/CAVE/databases/pubfig/download/%s\"%attrs_name)\n",
    "        print(\"done\")\n",
    "\n",
    "    #read attrs\n",
    "    df_attrs = pd.read_csv(\"lfw_attributes.txt\",sep='\\t',skiprows=1,)\n",
    "    df_attrs = pd.DataFrame(df_attrs.iloc[:,:-1].values, columns = df_attrs.columns[1:])\n",
    "    df_attrs.imagenum = df_attrs.imagenum.astype(np.int64)\n",
    "\n",
    "\n",
    "    #read photos\n",
    "    dirname = raw_images_name if use_raw else images_name\n",
    "    photo_ids = []\n",
    "    for dirpath, dirnames, filenames in os.walk(dirname):\n",
    "        for fname in filenames:\n",
    "            if fname.endswith(\".jpg\"):\n",
    "                fpath = os.path.join(dirpath,fname)\n",
    "                photo_id = fname[:-4].replace('_',' ').split()\n",
    "                person_id = ' '.join(photo_id[:-1])\n",
    "                photo_number = int(photo_id[-1])\n",
    "                photo_ids.append({'person':person_id,'imagenum':photo_number,'photo_path':fpath})\n",
    "\n",
    "    photo_ids = pd.DataFrame(photo_ids)\n",
    "\n",
    "    #mass-merge\n",
    "    #(photos now have same order as attributes)\n",
    "    df = pd.merge(df_attrs,photo_ids,on=('person','imagenum'))\n",
    "\n",
    "    assert len(df)==len(df_attrs),\"lost some data when merging dataframes\"\n",
    "\n",
    "    #image preprocessing\n",
    "    all_photos = df['photo_path'].apply(imread)\\\n",
    "                                 .apply(lambda img: img[dy:-dy,dx:-dx])\\\n",
    "                                 .apply(lambda img: resize(img, (dimx, dimy)))\n",
    "\n",
    "    all_photos = np.stack(all_photos.values).astype('uint8')\n",
    "    all_attrs = df.drop([\"photo_path\",\"person\",\"imagenum\"],axis=1)\n",
    "\n",
    "    return all_photos,all_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df99032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.initializers as I\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "from keras.layers import Input\n",
    "%matplotlib inline\n",
    "from keras.layers import Conv2D,Conv2DTranspose,Dropout,LeakyReLU\n",
    "from keras.layers import Flatten,Dense,BatchNormalization,Reshape\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model,Sequential\n",
    "from keras import backend as K\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f2d8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "plt.rcParams.update({'axes.titlesize': 'small'})\n",
    "\n",
    "data,attrs = fetch_lfw_dataset(dimx=36,dimy=36)\n",
    "\n",
    "\n",
    "IMG_SHAPE = data.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb5d57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.array(data).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e22c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (data - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96625949",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616f21dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Sequential()\n",
    "\n",
    "discriminator.add(Conv2D(128, (3,3), strides=(2,2), padding='same', input_shape=(36,36,3)))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "discriminator.add(Flatten()) #shape of 8192\n",
    "discriminator.add(Dropout(0.4))\n",
    "discriminator.add(Dense(2, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c243e4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_SIZE = 256\n",
    "generator=Sequential()\n",
    "generator.add(Dense(9*9*128, input_dim=CODE_SIZE))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(Reshape((9,9,128)))\n",
    "generator.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "generator.add(Conv2D(3, (8,8), activation='tanh', padding='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9183708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_noise_batch(bsize):\n",
    "    return np.random.normal(size=(bsize, CODE_SIZE)).astype('float32')\n",
    "\n",
    "def sample_data_batch(bsize):\n",
    "    idxs = np.random.choice(np.arange(data.shape[0]), size=bsize)\n",
    "    return data[idxs]\n",
    "\n",
    "def sample_images(nrow,ncol, sharp=False):\n",
    "    images = generator.predict(sample_noise_batch(bsize=nrow*ncol))\n",
    "    #if np.var(images)!=0:\n",
    "        #images = images.clip(np.min(data),np.max(data))\n",
    "    for i in range(nrow*ncol):\n",
    "        plt.subplot(nrow,ncol,i+1)\n",
    "        if sharp:\n",
    "            plt.imshow(images[i].reshape(36,36,3),cmap=\"gray\", interpolation=\"none\")\n",
    "        else:\n",
    "            plt.imshow(images[i].reshape(36,36,3),cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "def sample_probas(bsize):\n",
    "    plt.title('Generated vs real data')\n",
    "    plt.hist(np.exp(discriminator.predict(sample_data_batch(bsize)))[:,1],\n",
    "             label='D(x)', alpha=0.5,range=[0,1])\n",
    "    plt.hist(np.exp(discriminator.predict(generator.predict(sample_noise_batch(bsize))))[:,1],\n",
    "             label='D(G(z))',alpha=0.5,range=[0,1])\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce859000",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_optimizer = tf.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "gen_optimizer = tf.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccaf019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from tqdm import tnrange\n",
    "\n",
    "for epoch in tnrange(20000):\n",
    "    \n",
    "\n",
    "\n",
    "    real_data = sample_data_batch(100)\n",
    "    noise = sample_noise_batch(100)\n",
    "\n",
    "\n",
    "    ########################\n",
    "    #discriminator training#\n",
    "    ########################\n",
    "    for i in range(2):\n",
    "\n",
    "\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "        logp_real = discriminator(real_data)\n",
    "\n",
    "        generated_data = generator(noise)\n",
    "\n",
    "        logp_gen = discriminator(generated_data)\n",
    "\n",
    "        d_loss = -tf.reduce_mean(tf.math.log(logp_real[:,1] + logp_gen[:,0]))\n",
    "\n",
    "        #regularize\n",
    "        d_loss += tf.reduce_mean(discriminator.layers[-1].kernel**2)\n",
    "\n",
    "        #optimize\n",
    "\n",
    "\n",
    "        gradients = tape.gradient(d_loss, discriminator.trainable_weights)\n",
    "        disc_optimizer.apply_gradients(zip(gradients, discriminator.trainable_weights))\n",
    "\n",
    "    print(\"discriminator loss\",d_loss)\n",
    "\n",
    "\n",
    "    ########################\n",
    "    ###generator training###\n",
    "    ########################\n",
    "\n",
    "    for i in range(10):\n",
    "        \n",
    "\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "\n",
    "            generated_data = generator(np.random.randn(100, 256))\n",
    "            logp_gen = discriminator(generated_data)\n",
    "            g_loss = -tf.reduce_mean(tf.math.log(logp_gen[:, 1]))\n",
    "\n",
    "            gradients = tape.gradient(g_loss, generator.trainable_variables)\n",
    "            gen_optimizer.apply_gradients(zip(gradients, generator.trainable_variables))\n",
    "\n",
    "    print(\"generator loss\",g_loss)\n",
    "\n",
    "    if epoch %100==0:\n",
    "        display.clear_output(wait=True)\n",
    "        sample_images(2,3,True)\n",
    "        sample_probas(1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
